{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chapter7.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNF+eQJ/AeOYJEMnz0ctpDA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"qyf3Gp63sXo1"},"source":["#Functional API\n","from keras import Input,layers\n","\n","input_tensor = Input(shape=(32,)) #建立一個輸入張量\n","print(input_tensor.shape)\n","\n","dense = layers.Dense(16,activation='relu') #建立一個Dense層，並將其想像成一個函數\n","output_tensor = dense(input_tensor) # 將張量輸入層函數，他會回傳經處理後的結果張亮\n","print(output_tensor.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ELGXtmvFtQti"},"source":["#序列式(Sequential)建立模型\n","from keras.models import Sequential,Model\n","from keras import layers,Input\n","\n","model=Sequential()\n","model.add(layers.Dense(32,activation='relu',input_shape=(64,)))\n","model.add(layers.Dense(32,activation='relu'))\n","model.add(layers.Dense(32,activation='softmax'))\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"08f0cosmtXjQ"},"source":["#函數式(API)建立模型\n","#透過建立Model物件\n","input_tensor = Input(shape=(64,)) # 建立一個初始張量\n","\n","x = layers.Dense(32,activation='relu')(input_tensor)\n","\n","y = layers.Dense(32,activation='relu')(x)\n","\n","output_tensor = layers.Dense(10,activation='softmax')(y)\n","\n","model = Model(input_tensor,output_tensor)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mUas0EEctZ3Y"},"source":["#如果用完全不相干的輸入和輸出張量去建構模型。\n","#因為Keras找不到相關資訊，導致執行時會生錯誤。\n","unrelated_input = Input(shape=(32,))\n","bad_model = model = Model(unrelated_input,output_tensor)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PsNgEmfUthN0"},"source":["#在編譯、訓練或驗證此Model物件時，API的功能與序列式模型相同\n","model.compile(optimizer='rmsprop',loss='categorical_crossentropy')\n","import numpy as np\n","\n","x_train = np.random.random((1000,64))\n","y_train = np.random.random((1000,10))\n","\n","# 將訓練輸入模型進行訓練\n","model.fit(x_train,y_train,epochs=10,batch_size=128)\n","score = model.evaluate(x_train,y_train)\n","print(score)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6kqh7yPNtkc_"},"source":["#多輸入模型\n","from keras import Model \n","from keras import layers\n","from keras import Input\n","\n","text_vocabulary_size = 10000\n","question_vocabulary_size = 10000\n","answer_vocabulary_size = 500\n","\n","text_input = Input(shape=(None,),dtype='int32',name='text')\n","embedded_text = layers.Embedding(text_vocabulary_size,64)(text_input)\n","print(embedded_text.shape)\n","encoded_text = layers.LSTM(32)(embedded_text)\n","print(encoded_text.shape)\n","\n","question_input = Input(shape=(None,),dtype='int32',name='question')\n","embedded_question = layers.Embedding(question_vocabulary_size,32)(question_input)\n","print(embedded_question.shape)\n","encoded_question = layers.LSTM(16)(embedded_question)\n","print(encoded_question.shape)\n","\n","concatenated = layers.concatenate([encoded_question,encoded_text],axis=1)\n","print(concatenated.shape)\n","\n","answer = layers.Dense(answer_vocabulary_size,activation='softmax')(concatenated)\n","print(answer.shape)\n","\n","model = Model([text_input,question_input],answer)\n","model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MMweeD-5tmh1"},"source":["#訓練雙輸入模型的方法\n","import numpy as np\n","\n","num_samples = 1000\n","max_length = 100\n","\n","# 產生虛擬text資料：1000筆，每筆100個字(數字)\n","text = np.random.randint(1,text_vocabulary_size,size = (num_samples,max_length))\n","print(text.shape)\n","\n","# 產生虛擬question資料：1000筆，每筆100個字(數字)\n","question = np.random.randint(1,question_vocabulary_size,size = (num_samples,max_length))\n","print(question.shape)\n","\n","# 產生虛擬answer資料：1000筆，每筆100個字(數字)\n","answers = np.zeros(shape=(num_samples,answer_vocabulary_size),dtype='int32')\n","\n","for answer in answers:\n","  answer[np.random.randint(answer_vocabulary_size)]=1\n","print(answers.shape)\n","\n","# 訓練方法1：使用list將送入資料進行訓練\n","model.fit([text,question],answers,epochs=10,batch_size=128)\n","\n","# 訓練方法2；使用dict將送入資料進行訓練，鍵為Input層的名稱，值為Numpy的值\n","model.fit({'text':text,'question':question},answers,epochs=10,batch_size=128)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L0xYMe2gttCt"},"source":["#多輸出模型\n","from keras import layers,Input\n","from keras.models import Model\n","\n","vocabulary_size = 50000\n","num_income_groups = 10 #將收入分成10群\n","\n","posts_input = Input(shape=(None,),dtype='int32',name='posts')\n","\n","# 用函數式API將輸入向量傳入Embedding層，得到維度為256的崁入向量\n","embedding_posts = layers.Embedding(vocabulary_size,256)(posts_input)\n","print(embedding_posts.shape)\n","\n","# 以函數式API將砍入向量傳入一層層之中處理\n","x = layers.Conv1D(128,5,activation='relu')(embedding_posts)\n","x = layers.MaxPooling1D(5)(x)\n","x = layers.Conv1D(256,5,activation='relu')(x)\n","x = layers.Conv1D(256,5,activation='relu')(x)\n","x = layers.MaxPooling1D(5)(x)\n","x = layers.Conv1D(256,5,activation='relu')(x)\n","x = layers.Conv1D(256,5,activation='relu')(x)\n","x = layers.GlobalMaxPooling1D()(x)\n","x = layers.Dense(128,activation='relu')(x)\n","print(x.shape) # 走過一連串層後，x.shape為(?,128)\n","\n","#======================================================================#\n","#將x向量分別送到3個輸入層\n","#======================================================================#\n","# 1. 預測年紀的輸出層：純量迴歸任務\n","age_prediction = layers.Dense(1,name='age')(x)\n","\n","# 2. 預測收入族群的輸出層：多分類任務\n","income_prediction = layers.Dense(num_income_groups,activation='softmax',name='income')(x)\n","\n","# 3. 預測性別的輸出層：二元分類任務\n","gender_prediction = layers.Dense(1,activation='softmax',name='gender')(x)\n","\n","#======================================================================#\n","#用輸入向量與輸出向量實例化Model物件\n","#======================================================================#\n","model = Model(posts_input,[age_prediction,income_prediction,gender_prediction])\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lebCjEWrt267"},"source":["#1x1卷積 (瓶頸層)\n","from keras import layers,Input\n","\n","x = Input(batch_shape=(1000,28,28,256))\n","print(x.shape)\n","\n","branch_a = layers.Conv2D(64,1,activation='relu',strides=2)(x) #使用步長參數=2的進行1/2採樣\n","print(\"分支a\",branch_a.shape)\n","\n","branch_b = layers.Conv2D(64,1,activation='relu')(x) # 進行1x1逐點卷積，故shape大小不變\n","branch_b = layers.Conv2D(128,1,activation='relu',strides=2,padding='same')(branch_b) # 進行3X3空間卷積，並使用步長參數=2 進行1/2採樣\n","print(\"分支b\",branch_b.shape)\n","\n","branch_c = layers.AveragePooling2D(3,strides=2,padding='same')(x) # 採樣發生在平均池化中\n","branch_c = layers.Conv2D(128,1,activation='relu',padding='same')(branch_c) \n","print(\"分支c\",branch_c.shape)\n","\n","branch_d = layers.Conv2D(128,1,activation='relu')(x)\n","branch_d = layers.Conv2D(128,3,activation='relu',padding='same')(branch_d) # 進行3X3空間卷積，並使用步長參數=2 進行1/2採樣\n","branch_d = layers.Conv2D(128,3,activation='relu',strides=2,padding='same')(branch_d) # 進行3X3空間卷積，並使用步長參數=2 進行1/2採樣\n","print(\"分支d\",branch_d.shape)\n","\n","#================================================================#\n","#串接分支輸出以取得模組輸出\n","output = layers.concatenate([branch_a,branch_b,branch_c,branch_d],axis=-1)\n","print(output.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GbAU4oKNt7IM"},"source":["#線性轉換 Linear Transformations\n","#存在一個函數(也可以視為矩陣) T 可以將 R^m 空間的向量(張量)對應(轉換)到 R^n 空間的向量(張量),只要 R^n 空間的任意向量 u v符合以下兩個條件即可稱此轉換為線性轉換：\n","\n","#可加性\n","#齊次性\n","from keras import layers,Input\n","\n","x = Input(batch_shape=(1000,32,32,128)) # 定義4D張量 x\n","y = layers.Conv2D(128,3,activation='relu',padding='same')(x)\n","z = layers.Conv2D(128,3,activation='relu',padding='same')(y)\n","\n","op = layers.add([z,x])\n","print(op.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZjNs89JNt-Ha"},"source":["from keras import layers,Input\n","\n","x = Input(batch_shape=(1000,32,32,128)) # 定義4D張量 x\n","y = layers.Conv2D(128,3,activation='relu',padding='same')(x)\n","z = layers.Conv2D(128,3,activation='relu',padding='same')(y)\n","print(z.shape)\n","\n","t = layers.MaxPool2D(2,strides=2)(z)\n","print(t.shape)\n","\n","residual = layers.Conv2D(128,1,strides=2,padding='same')(x) # 對張量進行線性轉換以縮小採樣，並將channel降低盛與張量t相同的128\n","print(residual.shape)\n","\n","op = layers.add([t,residual])\n","print(op.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aa_7zz9NuAXS"},"source":["#孿生LSTM (Siamese LSTM)\n","from keras import layers,Input\n","from keras.models import Model\n","\n","lstm = layers.LSTM(32)\n","left_input = Input(shape=(None,128))\n","print(left_input.shape)\n","left_output = lstm(left_input)\n","print(left_output.shape)\n","\n","right_input = Input(shape=(None,128))\n","print(right_input.shape)\n","right_output = lstm(right_input)\n","print(right_output.shape)\n","\n","merged = layers.concatenate([left_output,right_output],axis=-1) # 將向量串接\n","print(merged.shape)\n","\n","predictions = layers.Dense(1,activation='sigmoid')(merged)\n","model = Model([left_input,right_input],predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uMERPO2-uGA6"},"source":["#不需要兩個獨立模型自左右鏡頭萃取視覺特徵，可以藉由同一個層來一起進行萃取\n","from keras import layers\n","from keras import applications\n","from keras import Input\n","\n","xception_base = applications.Xception(weights=None,include_top=False)\n","\n","left_input = Input(shape=(250,250,3))\n","right_input = Input(shape=(250,250,3))\n","\n","left_features = xception_base(left_input)\n","right_features = xception_base(right_input)\n","\n","print(left_features.shape)\n","print(right_features.shape)\n","\n","merged_features = layers.concatenate([left_features,right_features],axis=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nZ60QoE_qgxq"},"source":["#EarlyStopping 與 ModelCheckpoint 回呼\n","import keras\n","\n","callbacks_list = [\n","    keras.callbacks.EarlyStopping(monitor='val_acc',patience=1),\n","    keras.callbacks.ModelCheckpoint(filepath='my_model.ht',monitor='val_acc',save_best_only=True)\n","]\n","\n","model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n","\n","model.fit(x,y,validation_data=(x_val,y_val),epochs=10,batch_sizes=32,callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3nOW7VFcqkAg"},"source":["#RedeuceLROnPlateau 回呼\n","import keras\n","\n","callbacks_list = [keras.callbacks.RedeuceLROnPlateau(monitor='val_loss',factor=0.1,patience=10)]\n","\n","model.fit(x,y,validation_data=(x_val,y_val),epochs=10,batch_sizes=32,callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vktT2DyQqmv4"},"source":["#撰寫自己的回呼\n","import keras \n","import numpy as np \n","\n","class ActivationLogger(keras.callbacks.Callback): # 繼承Callback類別\n","\n","    def set_model(self,model):\n","        self.model = model\n","        layer_outputs = [layers.output for layer in model.layers]\n","        self.activations_model = keras.models.Model(model.input,layer_outputs)\n","\n","    def on_epoch_end(self,epoch,logs=None):\n","        if self.validation is None:\n","            raise RuntimeError(Requires validation_data')\n","\n","        validation_sample = self.validation_data[0][0:1]\n","        activations = self.activations_model.predict(validation_sample)\n","        f = open('validation_at_epoch',str(epoch)+'.npz','w')\n","        np.save(f,activations)\n","        f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wv2sjiKwqrVK"},"source":["#使用Tensor內建的文字分類模型\n","import keras\n","from keras import layers\n","from keras.datasets import imdb\n","from keras.preprocessing import sequence\n","\n","max_features = 2000\n","max_len = 500\n","\n","(x_train,y_train),(x_test,y_test) = imdb.load_data(num_words=max_features)\n","x_train = sequence.pad_sequences(x_train,maxlen=max_len)\n","x_test = sequence.pad_sequences(x_test,maxlen=max_len)\n","\n","model = keras.models.Sequential()\n","model.add(layers.Embedding(max_features,128,input_length=max_len,name='embed'))\n","model.add(layers.Conv1D(32,7,activation='relu'))\n","model.add(layers.MaxPool1D(5))\n","model.add(layers.Conv1D(32,7,activation='relu'))\n","model.add(layers.GlobalMaxPool1D())\n","model.add(layers.Dense(1))\n","model.summary()\n","\n","model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nMnZU8z5qvM-"},"source":["#使用TensorBoard回呼來訓練模型\n","callbacks_list = [\n","    keras.callbacks.TensorBoard(log_dir='my_log_dir',histogram_freq=1,embeddings_freq=1)\n","]\n","\n","history = model.fit(x_train,y_train,epochs=20,batch_size=128,validation_split=0.2,callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mp4064fMqygn"},"source":["from keras.utils import plot_model\n","plot_model(model,to_file='model.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_C3npm6qq0mg"},"source":["from keras.utils import plot_model\n","plot_model(model,show_shapes=True,to_file='model.png')"],"execution_count":null,"outputs":[]}]}